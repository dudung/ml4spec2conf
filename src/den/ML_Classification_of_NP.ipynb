{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f8960d",
   "metadata": {},
   "source": [
    "# Identifying Nanoparticles Aggregate from Its Scattering Spectra with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b55279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_excel\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89e9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lam_max1      csc_max1  lam_min       csc_min   lam_fwhm1         c_mid  \\\n",
      "0     408.0  1.601443e-14      430  1.309453e-14  452.547971  2.136383e-14   \n",
      "1     408.0  1.601331e-14      430  1.309381e-14  452.547915  2.136334e-14   \n",
      "2     408.0  1.601075e-14      430  1.309218e-14  452.547788  2.136220e-14   \n",
      "3     408.0  1.600855e-14      430  1.309076e-14  452.547708  2.136121e-14   \n",
      "4     408.0  1.600793e-14      430  1.309029e-14  452.547746  2.136089e-14   \n",
      "\n",
      "   lam_max2      csc_max2   lam_fwhm2       fwhm  ...  posisi2  posisi3  \\\n",
      "0       462  2.963313e-14  471.424766  18.876794  ...        0        0   \n",
      "1       462  2.963287e-14  471.424929  18.877014  ...        0        0   \n",
      "2       462  2.963222e-14  471.425311  18.877523  ...        0        0   \n",
      "3       462  2.963166e-14  471.425636  18.877928  ...        0        0   \n",
      "4       462  2.963148e-14  471.425723  18.877976  ...        0        0   \n",
      "\n",
      "   posisi4  posisi5  arah_k  arah_E  sb_putar  sudut1  sudut2  ket  \n",
      "0        0        0       3       2         1       0       0    0  \n",
      "1        0        0       3       2         1       1       5    0  \n",
      "2        0        0       3       2         1       3       0    0  \n",
      "3        0        0       3       2         1       4       5    0  \n",
      "4        0        0       3       2         1       6       0    0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/tanpabola3-1.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "dataset = read_excel(url, names=names, header=None)\n",
    "\n",
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cf9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Cek kolom yang punya nilai yang sama\n",
    "df_sama = dataset[dataset['lam_max1'] == dataset['lam_max2']]\n",
    "print(len(df_sama[['lam_max1', 'lam_max2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output data\n",
    "X = dataset.iloc[:,0:10].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df196d84",
   "metadata": {},
   "source": [
    "## 0. Selecting Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot check algorithms\n",
    "models = {\n",
    "    'LR' : make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', multi_class='ovr')),\n",
    "    'LDA' : LinearDiscriminantAnalysis(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'CART' : DecisionTreeClassifier(),\n",
    "    'NB' : GaussianNB(),\n",
    "    'SVM' : SVC(gamma='auto')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot check algorithms\n",
    "models = {\n",
    "    'LR' : make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', multi_class='ovr')),\n",
    "    'LDA' : LinearDiscriminantAnalysis(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'CART' : DecisionTreeClassifier(),\n",
    "    'NB' : GaussianNB(),\n",
    "    'SVM' : make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83be865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot check algorithms\n",
    "models = {\n",
    "    'LR' : make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', multi_class='ovr')),\n",
    "    'LDA' : LinearDiscriminantAnalysis(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'CART' : DecisionTreeClassifier(),\n",
    "    'NB' : GaussianNB(),\n",
    "    'SVM' : make_pipeline(StandardScaler(), SVC(gamma='auto', kernel='rbf'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f369e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Evaluation storage\n",
    "results = {name: {'accuracy': [], 'precision': []} for name in models}\n",
    "\n",
    "# Training and evaluation\n",
    "for name, model in models.items():\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average=None)\n",
    "\n",
    "        results[name]['accuracy'].append(acc)\n",
    "        results[name]['precision'].append(prec)\n",
    "\n",
    "# Print results\n",
    "for name, scores in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  Mean Accuracy: {np.mean(scores['accuracy']):.4f}\")\n",
    "    print(f\"  Mean Precision: {np.mean(scores['precision']):.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38ddb7",
   "metadata": {},
   "source": [
    "## 1. Validation for `tanpabola3.xlsx` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/tanpabola3-1.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "dataset = read_excel(url, names=names, header=None)\n",
    "\n",
    "# Define input and output data\n",
    "X = dataset.iloc[:,0:10].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = dataset[dataset['ket']==0].sample(n=189, random_state=42)\n",
    "class_1 = dataset[dataset['ket']==1]\n",
    "class_2 = dataset[dataset['ket']==2].sample(n=189, random_state=42)\n",
    "\n",
    "balance_df = pd.concat([class_0, class_1, class_2])\n",
    "\n",
    "balance_df = balance_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "dataset = balance_df\n",
    "X = dataset.iloc[:,0:10].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_valid))\n",
    "print(len(y_valid)/(len(y_train) + len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a text file\n",
    "with open(\"output_validation_tanpabola3_50.txt\", \"w\") as f:\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        y_predict = model.predict(X_valid)\n",
    "        report = classification_report(y_valid, y_predict)\n",
    "        cf = confusion_matrix(y_valid, y_predict)\n",
    "\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"confusion matrix:\\n {cf}\\n\")\n",
    "        f.write(f\"classification report: \\n {report}\\n\")\n",
    "        f.write(f\"=====================================================\\n\")\n",
    "print(\"Evaluation results exported to .txt file\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab04fb9",
   "metadata": {},
   "source": [
    "### - Testing with Data `3bola.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/3_sph.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "bola3 = read_excel(url, names=names, header=None)\n",
    "\n",
    "# Define input and output data\n",
    "X_bola3 = bola3.iloc[:,0:10].values\n",
    "y_bola3 = bola3.iloc[:,20].values\n",
    "\n",
    "print(len(X_bola3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bola3['ket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_bola3\n",
    "X_valid = X_bola3\n",
    "\n",
    "#y_valid = y_train\n",
    "#X_valid = X_train\n",
    "# Write results to a text file\n",
    "with open(\"output_validation_bola3-100.txt\", \"w\") as f:\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        y_predict = model.predict(X_valid)\n",
    "        report = classification_report(y_valid, y_predict)\n",
    "        cf = confusion_matrix(y_valid, y_predict)\n",
    "\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"confusion matrix:\\n {cf}\\n\")\n",
    "        f.write(f\"classification report: \\n {report}\\n\")\n",
    "        f.write(f\"=====================================================\\n\")\n",
    "print(\"Evaluation results exported to .txt file\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d365a",
   "metadata": {},
   "source": [
    "### - Testing with 20 data `bola3.xlsx` on each group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45def671",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_bola3\n",
    "X_valid = X_bola3\n",
    "# Write results to a text file\n",
    "with open(\"output_validation_bola3_20-50.txt\", \"w\") as f:\n",
    "    for i in range(int(np.round(len(y_bola3)/50))):\n",
    "        row = i*50\n",
    "        itv = 20 + (i*50)\n",
    "        X_valid = X_bola3[row:itv,:] \n",
    "        y_valid = y_bola3[row:itv]\n",
    "\n",
    "        f.write(f\"=========================( {i+1} )==========================\\n\")\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train,y_train)\n",
    "            y_predict = model.predict(X_valid)\n",
    "            report = classification_report(y_valid, y_predict, output_dict=True)\n",
    "            cf = confusion_matrix(y_valid, y_predict)\n",
    "\n",
    "            filtered_report = {k:v for k, v in report.items() if k not in ('accuracy','macro avg', 'weighted avg', 'micro avg')}\n",
    "            df = pd.DataFrame(filtered_report).T\n",
    "            acc = report['accuracy']\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"confusion matrix:\\n {cf}\\n\")\n",
    "            f.write(f\"classification report: \\n accuracy = {acc}\\n {df[['precision', 'recall', 'f1-score']]}\\n\")\n",
    "            f.write(f\"------------------------------------------------------------\\n\")\n",
    "print(\"Evaluation results exported to .txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e946ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bola3_5070 = X_bola3[50:70,:]\n",
    "y_bola3_5070 = y_bola3[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models['SVM'].fit(X_train,y_train)\n",
    "model2 = models['CART'].fit(X_train,y_train)\n",
    "y_predict1 = model1.predict(X_bola3_5070)\n",
    "y_predict2 = model2.predict(X_bola3_5070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model: SVM')\n",
    "print(f'actuals: {y_bola3_5070}')\n",
    "print(f'predict: {y_predict1}')\n",
    "print(\"================\")\n",
    "print('Model: CART')\n",
    "print(f'actuals: {y_bola3_5070}')\n",
    "print(f'predict: {y_predict2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "#bola3[columns][70-7:70]\n",
    "bola3[columns][50:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bola3_300320 = X_bola3[300:320,:]\n",
    "y_bola3_300320 = y_bola3[300:320]\n",
    "\n",
    "y_predict3 = model1.predict(X_bola3_300320)\n",
    "y_predict4 = model2.predict(X_bola3_300320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model: SVM')\n",
    "print(f'actuals: {y_bola3_300320}')\n",
    "print(f'predict: {y_predict3}')\n",
    "print(\"================\")\n",
    "print('Model: CART')\n",
    "print(f'actuals: {y_bola3_300320}')\n",
    "print(f'predict: {y_predict4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134dac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "#bola3[columns][320-5:320]\n",
    "bola3[columns][300:308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde23e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../data/raw/3\"\n",
    "\n",
    "#select the files you want to plot\n",
    "selected_files = ['10011_Y4_00.xlsx', '10011_Y4_15.xlsx', '10011_Y4_30.xlsx', '10011_Y4_45.xlsx',\n",
    "                  '10011_Y4_60.xlsx', '10011_Y4_75.xlsx', '10011_Y4_90.xlsx']\n",
    "\n",
    "\n",
    "lam = np.arange(350,851,2)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(folder_path,file)\n",
    "\n",
    "    df = read_excel(file_path, header=None)\n",
    "\n",
    "    csca = df.iloc[0]\n",
    "\n",
    "    if len(csca) != len(lam):\n",
    "        print(f\"Warning: {file} has {len(csca)} values but x has {len(lam)} points\")\n",
    "        continue\n",
    "    \n",
    "    plt.plot(lam, csca, label=file[-7:-5])\n",
    "\n",
    "plt.xlabel('wavelength (nm)')\n",
    "plt.ylim([0,1.5E-13])\n",
    "plt.ylabel('Csca (m$^2$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../data/raw/3\"\n",
    "\n",
    "#select the files you want to plot\n",
    "selected_files = ['00111_Y4_00.xlsx', '00111_Y4_15.xlsx', '00111_Y4_30.xlsx',\n",
    "                  '00111_Y4_45.xlsx', '00111_Y4_60.xlsx', '00111_Y4_75.xlsx', '00111_Y4_90.xlsx',\n",
    "                  '01011_X1_30.xlsx']\n",
    "\n",
    "\n",
    "lam = np.arange(350,851,2)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(folder_path,file)\n",
    "\n",
    "    df = read_excel(file_path, header=None)\n",
    "\n",
    "    csca = df.iloc[0]\n",
    "\n",
    "    if len(csca) != len(lam):\n",
    "        print(f\"Warning: {file} has {len(csca)} values but x has {len(lam)} points\")\n",
    "        continue\n",
    "    \n",
    "    plt.plot(lam, csca, label=file[-7:-5])\n",
    "\n",
    "plt.xlabel('wavelength (nm)')\n",
    "plt.ylim([0,1.5E-13])\n",
    "plt.ylabel('Csca (m$^2$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../data/raw/3\"\n",
    "\n",
    "#select the files you want to plot\n",
    "selected_files = ['10101_X1_00.xlsx', '10101_X1_15.xlsx', '10101_X1_30.xlsx',\n",
    "                  '10101_X1_45.xlsx', '10101_X1_60.xlsx', '10101_X1_75.xlsx', '10101_X1_90.xlsx']\n",
    "\n",
    "\n",
    "lam = np.arange(350,851,2)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(folder_path,file)\n",
    "\n",
    "    df = read_excel(file_path, header=None)\n",
    "\n",
    "    csca = df.iloc[0]\n",
    "\n",
    "    if len(csca) != len(lam):\n",
    "        print(f\"Warning: {file} has {len(csca)} values but x has {len(lam)} points\")\n",
    "        continue\n",
    "    \n",
    "    plt.plot(lam, csca, label=file[-7:-5])\n",
    "\n",
    "plt.xlabel('wavelength (nm)')\n",
    "plt.ylim([0,1.5E-13])\n",
    "plt.ylabel('Csca (m$^2$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../data/raw/3\"\n",
    "\n",
    "#select the files you want to plot\n",
    "selected_files = ['10011_Y4_00.xlsx', '10011_Y4_15.xlsx', '10011_Y4_30.xlsx',\n",
    "                  '10011_Y4_45.xlsx', '10011_Y4_90.xlsx']\n",
    "\n",
    "\n",
    "lam = np.arange(350,851,2)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(folder_path,file)\n",
    "\n",
    "    df = read_excel(file_path, header=None)\n",
    "\n",
    "    csca = df.iloc[0]\n",
    "\n",
    "    if len(csca) != len(lam):\n",
    "        print(f\"Warning: {file} has {len(csca)} values but x has {len(lam)} points\")\n",
    "        continue\n",
    "    \n",
    "    plt.plot(lam, csca, label=file[-7:-5])\n",
    "\n",
    "plt.xlabel('wavelength (nm)')\n",
    "plt.ylim([0,1.5E-13])\n",
    "plt.ylabel('Csca (m$^2$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613098d1",
   "metadata": {},
   "source": [
    "## 2. Validation for `bola12345.xlsx` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/bola12345-1.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "dataset = read_excel(url, names=names, header=None)\n",
    "\n",
    "# Define input and output data\n",
    "X = dataset.iloc[:,0:10].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d120713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dataset, x='fwhm', hue='ket', kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.8,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_valid))\n",
    "print(len(y_valid)/(len(y_train) + len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f58472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a text file\n",
    "with open(\"output_validation_bola12345.txt\", \"w\") as f:\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        y_predict = model.predict(X_valid)\n",
    "        report = classification_report(y_valid, y_predict)\n",
    "        cf = confusion_matrix(y_valid, y_predict)\n",
    "\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"confusion matrix:\\n {cf}\\n\")\n",
    "        f.write(f\"classification report: \\n {report}\\n\")\n",
    "        f.write(f\"=====================================================\\n\")\n",
    "print(\"Evaluation results exported to .txt file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0cda3",
   "metadata": {},
   "source": [
    "## 3. Using `2bola.xlsx` for Train Model to Predict Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbaa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/2_sph.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "dataset = read_excel(url, names=names, header=None)\n",
    "\n",
    "# Define input and output data\n",
    "X = dataset.iloc[:,0:10].values\n",
    "y = dataset.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaee6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_size=1\n",
    "\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"../../data/processed/den/Exp_2bola.xlsx\"\n",
    "names = ['lam_max1', 'csc_max1', 'lam_min', 'csc_min','lam_fwhm1','c_mid','lam_max2','csc_max2','lam_fwhm2','fwhm','posisi1','posisi2','posisi3','posisi4','posisi5','arah_k','arah_E','sb_putar','sudut1','sudut2','ket'] \n",
    "exp = read_excel(url, names=names, header=None)\n",
    "\n",
    "# Define input and output data\n",
    "X_exp = exp.iloc[:,0:10].values\n",
    "y_exp = exp.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1071e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_exp\n",
    "X_valid = X_exp\n",
    "# Write results to a text file\n",
    "with open(\"output_validation_experiment_2.txt\", \"w\") as f:\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train,y_train)\n",
    "        y_predict = model.predict(X_valid)\n",
    "        report = classification_report(y_valid, y_predict)\n",
    "        cf = confusion_matrix(y_valid, y_predict)\n",
    "\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"confusion matrix:\\n {cf}\\n\")\n",
    "        f.write(f\"classification report: \\n {report}\\n\")\n",
    "        f.write(f\"=====================================================\\n\")\n",
    "print(\"Evaluation results exported to .txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa2930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
